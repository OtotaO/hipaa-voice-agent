version: '3.8'

# HIPAA-Compliant Voice Agent Stack
# Option A: Twilio + Pipecat + AWS Transcribe Medical + Self-hosted LLM

services:
  # ===========================================
  # Core Services
  # ===========================================
  
  # Pipecat Agent Runtime - Heart of the voice processing pipeline
  pipecat:
    build: 
      context: ./docker/pipecat
      dockerfile: Dockerfile
    container_name: hipaa-pipecat
    restart: unless-stopped
    env_file:
      - ./config/.env
    environment:
      - SERVICE_NAME=pipecat-agent
      - LOG_LEVEL=INFO
      - ENABLE_PHI_REDACTION=true
      - TLS_ENABLED=true
      - WEBHOOK_TIMEOUT=30
    ports:
      - "8080:8080"  # WebSocket for Twilio Media Streams
      - "8081:8081"  # Health check endpoint
    volumes:
      - ./src:/app/src:ro
      - ./config:/app/config:ro
      - pipecat-logs:/app/logs
    networks:
      - hipaa-network
    depends_on:
      - redis
      - temporal
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=pipecat,phi_handling=true"

  # ===========================================
  # LLM Service (Self-hosted)
  # ===========================================
  
  # vLLM for self-hosted Llama 3
  vllm:
    image: vllm/vllm-openai:latest
    container_name: hipaa-llm
    restart: unless-stopped
    environment:
      - MODEL_NAME=${LLM_MODEL:-meta-llama/Llama-3-70b-chat-hf}
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_ATTENTION_BACKEND=FLASH_ATTENTION
      - MAX_MODEL_LEN=4096
      - GPU_MEMORY_UTILIZATION=0.95
      - ENABLE_PREFIX_CACHING=true
    ports:
      - "8000:8000"
    volumes:
      - llm-models:/models
      - llm-cache:/root/.cache
    networks:
      - hipaa-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 5
    security_opt:
      - no-new-privileges:true

  # ===========================================
  # Temporal Workflow Engine
  # ===========================================
  
  # Temporal Server for durable workflows and audit trail
  temporal:
    image: temporalio/auto-setup:1.24.2
    container_name: hipaa-temporal
    restart: unless-stopped
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=${TEMPORAL_DB_PASSWORD}
      - POSTGRES_SEEDS=postgres:5432
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=false  # Disable Elasticsearch for PHI safety
      - SKIP_SCHEMA_SETUP=false
    ports:
      - "7233:7233"  # Temporal gRPC
    volumes:
      - temporal-data:/var/lib/temporal
      - ./config/temporal:/etc/temporal/config
    networks:
      - hipaa-network
    depends_on:
      - postgres
    healthcheck:
      test: ["CMD", "temporal", "admin", "cluster", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
    security_opt:
      - no-new-privileges:true

  # Temporal Web UI (optional, disable in production)
  temporal-ui:
    image: temporalio/ui:2.28.0
    container_name: hipaa-temporal-ui
    restart: unless-stopped
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    ports:
      - "8088:8080"
    networks:
      - hipaa-network
    depends_on:
      - temporal
    profiles:
      - development  # Only run in dev environment

  # Temporal Worker for executing workflows
  temporal-worker:
    build:
      context: ./docker/temporal-worker
      dockerfile: Dockerfile
    container_name: hipaa-temporal-worker
    restart: unless-stopped
    env_file:
      - ./config/.env
    environment:
      - TEMPORAL_HOST=temporal:7233
      - WORKER_NAMESPACE=medical
      - ENABLE_AUDIT_LOGGING=true
      - PHI_REDACTION=true
    volumes:
      - ./src/workflows:/app/workflows:ro
      - temporal-worker-logs:/app/logs
    networks:
      - hipaa-network
    depends_on:
      - temporal
    deploy:
      replicas: 2  # Run multiple workers for redundancy
    security_opt:
      - no-new-privileges:true

  # ===========================================
  # Data Storage (HIPAA-compliant configuration)
  # ===========================================
  
  # PostgreSQL for Temporal and application data
  postgres:
    image: postgres:16-alpine
    container_name: hipaa-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_MULTIPLE_DATABASES=temporal,medical
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256 --auth-local=scram-sha-256
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/postgres-init:/docker-entrypoint-initdb.d
    networks:
      - hipaa-network
    command: >
      postgres
      -c ssl=on
      -c ssl_cert_file=/var/lib/postgresql/server.crt
      -c ssl_key_file=/var/lib/postgresql/server.key
      -c shared_preload_libraries=pg_stat_statements
      -c log_statement=none  # Don't log queries (PHI risk)
      -c log_min_duration_statement=-1
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    security_opt:
      - no-new-privileges:true

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: hipaa-redis
    restart: unless-stopped
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --tcp-backlog 511
      --timeout 0
      --tcp-keepalive 300
      --protected-mode yes
      --save ""  # Disable RDB persistence for PHI safety
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - hipaa-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    security_opt:
      - no-new-privileges:true

  # ===========================================
  # FHIR Integration Service
  # ===========================================
  
  fhir-bridge:
    build:
      context: ./docker/fhir-bridge
      dockerfile: Dockerfile
    container_name: hipaa-fhir-bridge
    restart: unless-stopped
    env_file:
      - ./config/.env
    environment:
      - SERVICE_NAME=fhir-bridge
      - FHIR_VERSION=R4
      - ENABLE_AUDIT=true
      - CACHE_PHI=false
    ports:
      - "8082:8080"
    volumes:
      - ./src/integrations/fhir:/app/src:ro
      - fhir-logs:/app/logs
    networks:
      - hipaa-network
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    security_opt:
      - no-new-privileges:true

  # ===========================================
  # Monitoring & Observability (PHI-safe)
  # ===========================================
  
  # Prometheus for metrics (no PHI in metrics)
  prometheus:
    image: prom/prometheus:v2.51.2
    container_name: hipaa-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus:/etc/prometheus:ro
      - prometheus-data:/prometheus
    networks:
      - hipaa-network
    profiles:
      - monitoring
    security_opt:
      - no-new-privileges:true

  # Grafana for dashboards (read-only access to metrics)
  grafana:
    image: grafana/grafana:10.4.2
    container_name: hipaa-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
    ports:
      - "3000:3000"
    volumes:
      - ./config/grafana:/etc/grafana/provisioning:ro
      - grafana-data:/var/lib/grafana
    networks:
      - hipaa-network
    depends_on:
      - prometheus
    profiles:
      - monitoring
    security_opt:
      - no-new-privileges:true

  # ===========================================
  # Security & Compliance Tools
  # ===========================================
  
  # Audit log aggregator (PHI-safe logging)
  vector:
    image: timberio/vector:0.38.0-alpine
    container_name: hipaa-vector
    restart: unless-stopped
    volumes:
      - ./config/vector/vector.toml:/etc/vector/vector.toml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - vector-data:/var/lib/vector
    networks:
      - hipaa-network
    command: ["--config", "/etc/vector/vector.toml"]
    security_opt:
      - no-new-privileges:true

# ===========================================
# Networks
# ===========================================

networks:
  hipaa-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
    driver_opts:
      com.docker.network.bridge.name: br-hipaa
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "true"

# ===========================================
# Volumes (encrypted at rest)
# ===========================================

volumes:
  pipecat-logs:
    driver: local
    driver_opts:
      type: none
      o: bind,uid=1000,gid=1000
      device: ${HOST_LOGS_PATH:-./data/logs/pipecat}
  
  llm-models:
    driver: local
    driver_opts:
      type: none
      o: bind,uid=1000,gid=1000
      device: ${HOST_MODELS_PATH:-./data/models}
  
  llm-cache:
    driver: local
  
  temporal-data:
    driver: local
  
  temporal-worker-logs:
    driver: local
  
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind,uid=999,gid=999
      device: ${HOST_POSTGRES_PATH:-./data/postgres}
  
  redis-data:
    driver: local
  
  fhir-logs:
    driver: local
  
  prometheus-data:
    driver: local
  
  grafana-data:
    driver: local
  
  vector-data:
    driver: local

# ===========================================
# Deployment Notes:
# ===========================================
# 1. Ensure all volumes are encrypted at the host level
# 2. Set up proper backup procedures for persistent volumes
# 3. Configure firewall rules to restrict access
# 4. Enable audit logging for all services
# 5. Implement key rotation for all credentials
# 6. Set up monitoring alerts for PHI access patterns
# 7. Configure TLS certificates for all exposed services
# 8. Review and harden all default configurations
